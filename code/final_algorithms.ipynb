{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Algorithms\n",
    "> By Sayed Afnan Khazi(01JST21CB036), Venkat Bhaskar(01JST21CB049), G Rutvik(01JST21CB012), Sai Sujith(01JST21CB033)\n",
    "- This notebook showcases the implementation of Artificial Neural Networks, K-Nearest Neighbors, Decision Trees, Random Forest, Support Vector Machines, and Reinforcement Learning (Q-learning) on a financial dataset containing Alibaba's stock prices for the past many years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: absl-py==2.1.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: appnope==0.1.4 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (0.1.4)\n",
      "Requirement already satisfied: asttokens==2.4.1 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (2.4.1)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (1.6.3)\n",
      "Requirement already satisfied: certifi==2024.2.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer==3.3.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (3.3.2)\n",
      "Requirement already satisfied: comm==0.2.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (0.2.2)\n",
      "Requirement already satisfied: debugpy==1.8.1 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (1.8.1)\n",
      "Requirement already satisfied: decorator==5.1.1 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (5.1.1)\n",
      "Requirement already satisfied: executing==2.0.1 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (2.0.1)\n",
      "Requirement already satisfied: flatbuffers==24.3.25 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (24.3.25)\n",
      "Requirement already satisfied: gast==0.5.4 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (0.5.4)\n",
      "Requirement already satisfied: google-pasta==0.2.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (0.2.0)\n",
      "Requirement already satisfied: grpcio==1.64.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (1.64.0)\n",
      "Requirement already satisfied: h5py==3.11.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 15)) (3.11.0)\n",
      "Requirement already satisfied: idna==3.7 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 16)) (3.7)\n",
      "Requirement already satisfied: ipykernel==6.29.4 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 17)) (6.29.4)\n",
      "Requirement already satisfied: ipython==8.24.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 18)) (8.24.0)\n",
      "Requirement already satisfied: jedi==0.19.1 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 19)) (0.19.1)\n",
      "Requirement already satisfied: joblib==1.4.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 20)) (1.4.2)\n",
      "Requirement already satisfied: jupyter_client==8.6.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 21)) (8.6.2)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 22)) (5.7.2)\n",
      "Requirement already satisfied: keras==3.3.3 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 23)) (3.3.3)\n",
      "Requirement already satisfied: libclang==18.1.1 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 24)) (18.1.1)\n",
      "Requirement already satisfied: Markdown==3.6 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 25)) (3.6)\n",
      "Requirement already satisfied: markdown-it-py==3.0.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 26)) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe==2.1.5 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 27)) (2.1.5)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 28)) (0.1.7)\n",
      "Requirement already satisfied: mdurl==0.1.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 29)) (0.1.2)\n",
      "Requirement already satisfied: ml-dtypes==0.3.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 30)) (0.3.2)\n",
      "Requirement already satisfied: namex==0.0.8 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 31)) (0.0.8)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 32)) (1.6.0)\n",
      "Requirement already satisfied: numpy==1.26.4 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 33)) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum==3.3.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 34)) (3.3.0)\n",
      "Requirement already satisfied: optree==0.11.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 35)) (0.11.0)\n",
      "Requirement already satisfied: packaging==24.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 36)) (24.0)\n",
      "Requirement already satisfied: pandas==2.2.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 37)) (2.2.2)\n",
      "Requirement already satisfied: parso==0.8.4 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 38)) (0.8.4)\n",
      "Requirement already satisfied: pexpect==4.9.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 39)) (4.9.0)\n",
      "Requirement already satisfied: platformdirs==4.2.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 40)) (4.2.2)\n",
      "Requirement already satisfied: prompt-toolkit==3.0.43 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 41)) (3.0.43)\n",
      "Requirement already satisfied: protobuf==4.25.3 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 42)) (4.25.3)\n",
      "Requirement already satisfied: psutil==5.9.8 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 43)) (5.9.8)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 44)) (0.7.0)\n",
      "Requirement already satisfied: pure-eval==0.2.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 45)) (0.2.2)\n",
      "Requirement already satisfied: Pygments==2.18.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 46)) (2.18.0)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 47)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz==2024.1 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 48)) (2024.1)\n",
      "Requirement already satisfied: pyzmq==26.0.3 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 49)) (26.0.3)\n",
      "Requirement already satisfied: requests==2.32.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 50)) (2.32.2)\n",
      "Requirement already satisfied: rich==13.7.1 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 51)) (13.7.1)\n",
      "Requirement already satisfied: scikit-learn==1.5.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 52)) (1.5.0)\n",
      "Requirement already satisfied: scipy==1.13.1 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 53)) (1.13.1)\n",
      "Requirement already satisfied: six==1.16.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 54)) (1.16.0)\n",
      "Requirement already satisfied: stack-data==0.6.3 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 55)) (0.6.3)\n",
      "Requirement already satisfied: tensorboard==2.16.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 56)) (2.16.2)\n",
      "Requirement already satisfied: tensorboard-data-server==0.7.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 57)) (0.7.2)\n",
      "Requirement already satisfied: tensorflow==2.16.1 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 58)) (2.16.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.37.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 59)) (0.37.0)\n",
      "Requirement already satisfied: termcolor==2.4.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 60)) (2.4.0)\n",
      "Requirement already satisfied: threadpoolctl==3.5.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 61)) (3.5.0)\n",
      "Requirement already satisfied: tornado==6.4 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 62)) (6.4)\n",
      "Requirement already satisfied: traitlets==5.14.3 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 63)) (5.14.3)\n",
      "Requirement already satisfied: typing_extensions==4.12.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 64)) (4.12.0)\n",
      "Requirement already satisfied: tzdata==2024.1 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 65)) (2024.1)\n",
      "Requirement already satisfied: urllib3==2.2.1 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 66)) (2.2.1)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 67)) (0.2.13)\n",
      "Requirement already satisfied: Werkzeug==3.0.3 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 68)) (3.0.3)\n",
      "Requirement already satisfied: wrapt==1.16.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 69)) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from astunparse==1.6.3->-r requirements.txt (line 4)) (0.43.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from tensorboard==2.16.2->-r requirements.txt (line 56)) (65.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install all the requirements\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 00:00:50.210600: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Importing all the requirements. \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, precision_score, accuracy_score, recall_score, f1_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_table = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 1: Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m122/122\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Confusion Matrix for ratio 0.4:\n",
      " [[3010  374]\n",
      " [ 432   68]]\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Confusion Matrix for ratio 0.3:\n",
      " [[2304  223]\n",
      " [ 331   55]]\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "Confusion Matrix for ratio 0.2:\n",
      " [[1485  206]\n",
      " [ 219   32]]\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Confusion Matrix for ratio 0.1:\n",
      " [[797  41]\n",
      " [118  15]]\n",
      "\n",
      "Metrics for test size ratio 0.4:\n",
      "Precision: 0.15\n",
      "Accuracy: 0.79\n",
      "Recall: 0.14\n",
      "F1 Score: 0.14\n",
      "\n",
      "Metrics for test size ratio 0.3:\n",
      "Precision: 0.20\n",
      "Accuracy: 0.81\n",
      "Recall: 0.14\n",
      "F1 Score: 0.17\n",
      "\n",
      "Metrics for test size ratio 0.2:\n",
      "Precision: 0.13\n",
      "Accuracy: 0.78\n",
      "Recall: 0.13\n",
      "F1 Score: 0.13\n",
      "\n",
      "Metrics for test size ratio 0.1:\n",
      "Precision: 0.27\n",
      "Accuracy: 0.84\n",
      "Recall: 0.11\n",
      "F1 Score: 0.16\n",
      "\n",
      "Classification Report for the last ratio:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91       838\n",
      "           1       0.27      0.11      0.16       133\n",
      "\n",
      "    accuracy                           0.84       971\n",
      "   macro avg       0.57      0.53      0.53       971\n",
      "weighted avg       0.79      0.84      0.81       971\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "The predicted eligibility for the next person is: Not Eligible\n",
      "Results:\n",
      "Ratio Precision Accuracy Recall F1\n",
      "0.4\t0.1538\t0.7925\t0.1360\t0.1444\n",
      "0.3\t0.1978\t0.8098\t0.1425\t0.1657\n",
      "0.2\t0.1345\t0.7812\t0.1275\t0.1309\n",
      "0.1\t0.2679\t0.8363\t0.1128\t0.1587\n",
      "Average F1 0.1499\n",
      "Average Accuracy 0.8049\n",
      "Average Precision 0.1885\n",
      "Average Recall 0.1297\n"
     ]
    }
   ],
   "source": [
    "# Load data from a CSV file\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Preprocess data\n",
    "# Handling missing values (if any)\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert categorical columns to numerical values using one-hot encoding\n",
    "categorical_columns = ['Gender', 'Own_car', 'Own_property', 'Work_phone', 'Phone', 'Email', 'Income_type', 'Education_type', 'Family_status', 'Housing_type', 'Occupation_type']\n",
    "df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Feature selection\n",
    "# Assuming 'Target' is the target variable\n",
    "features = df.columns.difference(['ID', 'Target'])\n",
    "X = df[features]\n",
    "y = df['Target']\n",
    "\n",
    "# Training-testing ratios\n",
    "ratios = [0.4, 0.3, 0.2, 0.1]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for ratio in ratios:\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=0)\n",
    "    \n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Initialize the ANN\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(units=64, activation='relu'))\n",
    "    model.add(Dense(units=32, activation='relu'))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the ANN\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train the ANN\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=10, verbose=0)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix for ratio {ratio}:\\n\", cm)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision_q = precision_score(y_test, y_pred, zero_division=0)\n",
    "    accuracy_q = accuracy_score(y_test, y_pred)\n",
    "    recall_q = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1_q = f1_score(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    results[ratio] = {'precision': precision_q, 'accuracy': accuracy_q, 'recall': recall_q, 'f1': f1_q}\n",
    "\n",
    "# Display results\n",
    "for ratio, metrics in results.items():\n",
    "    print(f\"\\nMetrics for test size ratio {ratio}:\")\n",
    "    print(f\"Precision: {metrics['precision']:.2f}\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.2f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.2f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.2f}\")\n",
    "\n",
    "# Detailed classification report for the last test size ratio\n",
    "print(\"\\nClassification Report for the last ratio:\\n\", classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Get the most recent data point and format it as a DataFrame\n",
    "last_data_point = df[features].iloc[-1].to_frame().T\n",
    "\n",
    "# Standardize the last data point\n",
    "last_data_point_scaled = scaler.transform(last_data_point)\n",
    "\n",
    "# Predict the eligibility for the next data point\n",
    "predicted_movement = model.predict(last_data_point_scaled)\n",
    "predicted_movement = (predicted_movement > 0.5).astype(int)\n",
    "\n",
    "# Interpret the result\n",
    "movement_label = \"Eligible\" if predicted_movement[0][0] == 1 else \"Not Eligible\"\n",
    "print(f'The predicted eligibility for the next person is: {movement_label}')\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(\"Results:\")\n",
    "print(\"Ratio Precision Accuracy Recall F1\")\n",
    "for ratio, metrics in results.items():\n",
    "    print(f\"{ratio:}\\t{metrics['precision']:.4f}\\t{metrics['accuracy']:.4f}\\t{metrics['recall']:.4f}\\t{metrics['f1']:.4f}\")\n",
    "print(\"Average F1\",round(sum([ results[ratio]['f1'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Accuracy\",round(sum([ results[ratio]['accuracy'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Precision\",round(sum([ results[ratio]['precision'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Recall\",round(sum([ results[ratio]['recall'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "\n",
    "final_results_table.loc[len(final_results_table)] = ['ANN', \n",
    "                                                     round(sum([ results[ratio]['accuracy'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['precision'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['recall'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['f1'] for ratio in results.keys() ])/len(results.keys()),4)\n",
    "                                                    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 2: K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for ratio 0.4:\n",
      " [[3315   69]\n",
      " [ 483   17]]\n",
      "Confusion Matrix for ratio 0.3:\n",
      " [[2477   50]\n",
      " [ 376   10]]\n",
      "Confusion Matrix for ratio 0.2:\n",
      " [[1655   36]\n",
      " [ 242    9]]\n",
      "Confusion Matrix for ratio 0.1:\n",
      " [[826  12]\n",
      " [128   5]]\n",
      "\n",
      "Metrics for test size ratio 0.4:\n",
      "Precision: 0.20\n",
      "Accuracy: 0.86\n",
      "Recall: 0.03\n",
      "F1 Score: 0.06\n",
      "\n",
      "Metrics for test size ratio 0.3:\n",
      "Precision: 0.17\n",
      "Accuracy: 0.85\n",
      "Recall: 0.03\n",
      "F1 Score: 0.04\n",
      "\n",
      "Metrics for test size ratio 0.2:\n",
      "Precision: 0.20\n",
      "Accuracy: 0.86\n",
      "Recall: 0.04\n",
      "F1 Score: 0.06\n",
      "\n",
      "Metrics for test size ratio 0.1:\n",
      "Precision: 0.29\n",
      "Accuracy: 0.86\n",
      "Recall: 0.04\n",
      "F1 Score: 0.07\n",
      "\n",
      "Classification Report for the last ratio:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92       838\n",
      "           1       0.29      0.04      0.07       133\n",
      "\n",
      "    accuracy                           0.86       971\n",
      "   macro avg       0.58      0.51      0.49       971\n",
      "weighted avg       0.79      0.86      0.80       971\n",
      "\n",
      "The predicted eligibility for the next person is: Not Eligible\n",
      "Results:\n",
      "Ratio Precision Accuracy Recall F1\n",
      "0.4\t0.1977\t0.8579\t0.0340\t0.0580\n",
      "0.3\t0.1667\t0.8538\t0.0259\t0.0448\n",
      "0.2\t0.2000\t0.8568\t0.0359\t0.0608\n",
      "0.1\t0.2941\t0.8558\t0.0376\t0.0667\n",
      "Average F1 0.0576\n",
      "Average Accuracy 0.8561\n",
      "Average Precision 0.2146\n",
      "Average Recall 0.0333\n"
     ]
    }
   ],
   "source": [
    "# Load data from a CSV file\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Preprocess data\n",
    "# Handling missing values (if any)\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert categorical columns to numerical values using one-hot encoding\n",
    "categorical_columns = ['Gender', 'Own_car', 'Own_property', 'Work_phone', 'Phone', 'Email', 'Income_type', 'Education_type', 'Family_status', 'Housing_type', 'Occupation_type']\n",
    "df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Feature selection\n",
    "# Assuming 'Target' is the target variable\n",
    "features = df.columns.difference(['ID', 'Target'])\n",
    "X = df[features]\n",
    "y = df['Target']\n",
    "\n",
    "# Training-testing ratios\n",
    "ratios = [0.4, 0.3, 0.2, 0.1]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for ratio in ratios:\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=0)\n",
    "    \n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Initialize and train the KNN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=2)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix for ratio {ratio}:\\n\", cm)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision_q = precision_score(y_test, y_pred, zero_division=0)\n",
    "    accuracy_q = accuracy_score(y_test, y_pred)\n",
    "    recall_q = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1_q = f1_score(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    results[ratio] = {'precision': precision_q, 'accuracy': accuracy_q, 'recall': recall_q, 'f1': f1_q}\n",
    "\n",
    "# Display results\n",
    "for ratio, metrics in results.items():\n",
    "    print(f\"\\nMetrics for test size ratio {ratio}:\")\n",
    "    print(f\"Precision: {metrics['precision']:.2f}\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.2f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.2f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.2f}\")\n",
    "\n",
    "# Detailed classification report for the last test size ratio\n",
    "print(\"\\nClassification Report for the last ratio:\\n\", classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Get the most recent data point and format it as a DataFrame\n",
    "last_data_point = df[features].iloc[-1].to_frame().T\n",
    "\n",
    "# Standardize the last data point\n",
    "last_data_point_scaled = scaler.transform(last_data_point)\n",
    "\n",
    "# Predict the eligibility for the next data point\n",
    "predicted_eligibility = knn.predict(last_data_point_scaled)\n",
    "\n",
    "# Interpret the result\n",
    "eligibility_label = \"Eligible\" if predicted_eligibility[0] == 1 else \"Not Eligible\"\n",
    "print(f'The predicted eligibility for the next person is: {eligibility_label}')\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(\"Results:\")\n",
    "print(\"Ratio Precision Accuracy Recall F1\")\n",
    "for ratio, metrics in results.items():\n",
    "    print(f\"{ratio:}\\t{metrics['precision']:.4f}\\t{metrics['accuracy']:.4f}\\t{metrics['recall']:.4f}\\t{metrics['f1']:.4f}\")\n",
    "print(\"Average F1\",round(sum([ results[ratio]['f1'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Accuracy\",round(sum([ results[ratio]['accuracy'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Precision\",round(sum([ results[ratio]['precision'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Recall\",round(sum([ results[ratio]['recall'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "\n",
    "final_results_table.loc[len(final_results_table)] = ['KNN', \n",
    "                                                     round(sum([ results[ratio]['accuracy'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['precision'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['recall'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['f1'] for ratio in results.keys() ])/len(results.keys()),4)\n",
    "                                                    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 3: Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for ratio 0.4:\n",
      " [[2873  511]\n",
      " [ 422   78]]\n",
      "Confusion Matrix for ratio 0.3:\n",
      " [[2148  379]\n",
      " [ 320   66]]\n",
      "Confusion Matrix for ratio 0.2:\n",
      " [[1427  264]\n",
      " [ 202   49]]\n",
      "Confusion Matrix for ratio 0.1:\n",
      " [[729 109]\n",
      " [108  25]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87       838\n",
      "           1       0.19      0.19      0.19       133\n",
      "\n",
      "    accuracy                           0.78       971\n",
      "   macro avg       0.53      0.53      0.53       971\n",
      "weighted avg       0.78      0.78      0.78       971\n",
      "\n",
      "The predicted eligibility for the next individual is: Not Eligible\n",
      "Results:\n",
      "Ratio Precision Accuracy Recall F1\n",
      "0.4\t0.1324\t0.7598\t0.1560\t0.1433\n",
      "0.3\t0.1483\t0.7600\t0.1710\t0.1588\n",
      "0.2\t0.1565\t0.7600\t0.1952\t0.1738\n",
      "0.1\t0.1866\t0.7765\t0.1880\t0.1873\n",
      "Average F1 0.1658\n",
      "Average Accuracy 0.7641\n",
      "Average Precision 0.156\n",
      "Average Recall 0.1775\n"
     ]
    }
   ],
   "source": [
    "# Load data from the new CSV file\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# List of categorical features to encode\n",
    "categorical_features = ['Income_type', 'Education_type', 'Family_status', 'Housing_type', 'Occupation_type']\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for feature in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "    label_encoders[feature] = le\n",
    "\n",
    "# Feature selection - excluding 'ID' and 'Target'\n",
    "features = [col for col in df.columns if col not in ['ID', 'Target']]\n",
    "X = df[features]\n",
    "y = df['Target']\n",
    "\n",
    "# Training-testing ratios\n",
    "ratios = [0.4, 0.3, 0.2, 0.1]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for ratio in ratios:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=0)\n",
    "\n",
    "    # Model training\n",
    "    classifier = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix for ratio {ratio}:\\n\", cm)\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision_q = precision_score(y_test, y_pred)\n",
    "    accuracy_q = accuracy_score(y_test, y_pred)\n",
    "    recall_q = recall_score(y_test, y_pred)\n",
    "    f1_q = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results[ratio] = {'precision': precision_q, 'accuracy': accuracy_q, 'recall': recall_q, 'f1': f1_q}\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Get the most recent data point and format it as a DataFrame\n",
    "last_data_point = df[features].iloc[-1].to_frame().T\n",
    "\n",
    "# Predict the eligibility for the next individual\n",
    "predicted_eligibility = classifier.predict(last_data_point)\n",
    "\n",
    "# Interpret the result\n",
    "eligibility_label = \"Eligible\" if predicted_eligibility[0] == 1 else \"Not Eligible\"\n",
    "print(f'The predicted eligibility for the next individual is: {eligibility_label}')\n",
    "\n",
    "# Print results\n",
    "print(\"Results:\")\n",
    "print(\"Ratio Precision Accuracy Recall F1\")\n",
    "for ratio, metrics in results.items():\n",
    "    print(f\"{ratio:}\\t{metrics['precision']:.4f}\\t{metrics['accuracy']:.4f}\\t{metrics['recall']:.4f}\\t{metrics['f1']:.4f}\")\n",
    "print(\"Average F1\",round(sum([ results[ratio]['f1'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Accuracy\",round(sum([ results[ratio]['accuracy'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Precision\",round(sum([ results[ratio]['precision'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Recall\",round(sum([ results[ratio]['recall'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "\n",
    "final_results_table.loc[len(final_results_table)] = ['Decision Tree', \n",
    "                                                     round(sum([ results[ratio]['accuracy'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['precision'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['recall'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['f1'] for ratio in results.keys() ])/len(results.keys()),4)\n",
    "                                                    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 4: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for ratio 0.4:\n",
      " [[3382    2]\n",
      " [ 499    1]]\n",
      "Confusion Matrix for ratio 0.3:\n",
      " [[2523    4]\n",
      " [ 384    2]]\n",
      "Confusion Matrix for ratio 0.2:\n",
      " [[1687    4]\n",
      " [ 250    1]]\n",
      "Confusion Matrix for ratio 0.1:\n",
      " [[838   0]\n",
      " [133   0]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93       838\n",
      "           1       0.00      0.00      0.00       133\n",
      "\n",
      "    accuracy                           0.86       971\n",
      "   macro avg       0.43      0.50      0.46       971\n",
      "weighted avg       0.74      0.86      0.80       971\n",
      "\n",
      "The predicted eligibility for the next individual is: Not Eligible\n",
      "Results:\n",
      "Ratio Precision Accuracy Recall F1\n",
      "0.4\t0.3333\t0.8710\t0.0020\t0.0040\n",
      "0.3\t0.3333\t0.8668\t0.0052\t0.0102\n",
      "0.2\t0.2000\t0.8692\t0.0040\t0.0078\n",
      "0.1\t0.0000\t0.8630\t0.0000\t0.0000\n",
      "Average F1 0.0055\n",
      "Average Accuracy 0.8675\n",
      "Average Precision 0.2167\n",
      "Average Recall 0.0028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Load data from the new CSV file\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# List of categorical features to encode\n",
    "categorical_features = ['Income_type', 'Education_type', 'Family_status', 'Housing_type', 'Occupation_type']\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for feature in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "    label_encoders[feature] = le\n",
    "\n",
    "# Feature selection - excluding 'ID' and 'Target'\n",
    "features = [col for col in df.columns if col not in ['ID', 'Target']]\n",
    "X = df[features]\n",
    "y = df['Target']\n",
    "\n",
    "# Training-testing ratios\n",
    "ratios = [0.4, 0.3, 0.2, 0.1]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for ratio in ratios:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=0)\n",
    "\n",
    "    # Model training\n",
    "    classifier = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix for ratio {ratio}:\\n\", cm)\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision_q = precision_score(y_test, y_pred)\n",
    "    accuracy_q = accuracy_score(y_test, y_pred)\n",
    "    recall_q = recall_score(y_test, y_pred)\n",
    "    f1_q = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results[ratio] = {'precision': precision_q, 'accuracy': accuracy_q, 'recall': recall_q, 'f1': f1_q}\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Get the most recent data point and format it as a DataFrame\n",
    "last_data_point = df[features].iloc[-1].to_frame().T\n",
    "\n",
    "# Predict the eligibility for the next individual\n",
    "predicted_eligibility = classifier.predict(last_data_point)\n",
    "\n",
    "# Interpret the result\n",
    "eligibility_label = \"Eligible\" if predicted_eligibility[0] == 1 else \"Not Eligible\"\n",
    "print(f'The predicted eligibility for the next individual is: {eligibility_label}')\n",
    "\n",
    "# Print results\n",
    "print(\"Results:\")\n",
    "print(\"Ratio Precision Accuracy Recall F1\")\n",
    "for ratio, metrics in results.items():\n",
    "    print(f\"{ratio:}\\t{metrics['precision']:.4f}\\t{metrics['accuracy']:.4f}\\t{metrics['recall']:.4f}\\t{metrics['f1']:.4f}\")\n",
    "print(\"Average F1\",round(sum([ results[ratio]['f1'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Accuracy\",round(sum([ results[ratio]['accuracy'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Precision\",round(sum([ results[ratio]['precision'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Recall\",round(sum([ results[ratio]['recall'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "\n",
    "final_results_table.loc[len(final_results_table)] = ['Random Forest', \n",
    "                                                     round(sum([ results[ratio]['accuracy'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['precision'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['recall'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['f1'] for ratio in results.keys() ])/len(results.keys()),4)\n",
    "                                                    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 5: Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for ratio 0.4:\n",
      " [[3269  115]\n",
      " [ 479   21]]\n",
      "Confusion Matrix for ratio 0.3:\n",
      " [[2454   73]\n",
      " [ 370   16]]\n",
      "Confusion Matrix for ratio 0.2:\n",
      " [[1605   86]\n",
      " [ 239   12]]\n",
      "Confusion Matrix for ratio 0.1:\n",
      " [[791  47]\n",
      " [123  10]]\n",
      "\n",
      "Metrics for test size ratio 0.4:\n",
      "Precision: 0.15\n",
      "Accuracy: 0.85\n",
      "Recall: 0.04\n",
      "F1 Score: 0.07\n",
      "\n",
      "Metrics for test size ratio 0.3:\n",
      "Precision: 0.18\n",
      "Accuracy: 0.85\n",
      "Recall: 0.04\n",
      "F1 Score: 0.07\n",
      "\n",
      "Metrics for test size ratio 0.2:\n",
      "Precision: 0.12\n",
      "Accuracy: 0.83\n",
      "Recall: 0.05\n",
      "F1 Score: 0.07\n",
      "\n",
      "Metrics for test size ratio 0.1:\n",
      "Precision: 0.18\n",
      "Accuracy: 0.82\n",
      "Recall: 0.08\n",
      "F1 Score: 0.11\n",
      "\n",
      "Classification Report for the last ratio:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90       838\n",
      "           1       0.18      0.08      0.11       133\n",
      "\n",
      "    accuracy                           0.82       971\n",
      "   macro avg       0.52      0.51      0.50       971\n",
      "weighted avg       0.77      0.82      0.79       971\n",
      "\n",
      "The predicted eligibility for the next data point is: Not Eligible\n",
      "Results:\n",
      "Ratio Precision Accuracy Recall F1\n",
      "0.4\t0.1544\t0.8471\t0.0420\t0.0660\n",
      "0.3\t0.1798\t0.8479\t0.0415\t0.0674\n",
      "0.2\t0.1224\t0.8326\t0.0478\t0.0688\n",
      "0.1\t0.1754\t0.8249\t0.0752\t0.1053\n",
      "Average F1 0.0769\n",
      "Average Accuracy 0.8381\n",
      "Average Precision 0.158\n",
      "Average Recall 0.0516\n"
     ]
    }
   ],
   "source": [
    "# Load data from a CSV file\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Preprocess data\n",
    "# Handling missing values (if any)\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert categorical columns to numerical values using one-hot encoding\n",
    "categorical_columns = ['Gender', 'Own_car', 'Own_property', 'Work_phone', 'Phone', 'Email', 'Income_type', 'Education_type', 'Family_status', 'Housing_type', 'Occupation_type']\n",
    "df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Feature selection\n",
    "# Assuming 'Target' is the target variable\n",
    "features = df.columns.difference(['ID', 'Target'])\n",
    "X = df[features]\n",
    "y = df['Target']\n",
    "\n",
    "# Training-testing ratios\n",
    "ratios = [0.4, 0.3, 0.2, 0.1]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for ratio in ratios:\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=0)\n",
    "    \n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Initialize and train the SVM classifier\n",
    "    svm_classifier = SVC(kernel='sigmoid', random_state=0)\n",
    "    svm_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = svm_classifier.predict(X_test)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix for ratio {ratio}:\\n\", cm)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision_q = precision_score(y_test, y_pred, zero_division=0)\n",
    "    accuracy_q = accuracy_score(y_test, y_pred)\n",
    "    recall_q = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1_q = f1_score(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    results[ratio] = {'precision': precision_q, 'accuracy': accuracy_q, 'recall': recall_q, 'f1': f1_q}\n",
    "\n",
    "# Display results\n",
    "for ratio, metrics in results.items():\n",
    "    print(f\"\\nMetrics for test size ratio {ratio}:\")\n",
    "    print(f\"Precision: {metrics['precision']:.2f}\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.2f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.2f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.2f}\")\n",
    "\n",
    "# Detailed classification report for the last test size ratio\n",
    "print(\"\\nClassification Report for the last ratio:\\n\", classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Get the most recent data point and format it as a DataFrame\n",
    "last_data_point = df[features].iloc[-1].to_frame().T\n",
    "\n",
    "# Standardize the last data point\n",
    "last_data_point_scaled = scaler.transform(last_data_point)\n",
    "\n",
    "# Predict the eligibility for the next data point\n",
    "predicted_eligibility = svm_classifier.predict(last_data_point_scaled)\n",
    "\n",
    "# Interpret the result\n",
    "eligibility_label = \"Eligible\" if predicted_eligibility[0] == 1 else \"Not Eligible\"\n",
    "print(f'The predicted eligibility for the next data point is: {eligibility_label}')\n",
    "\n",
    "# Print results\n",
    "print(\"Results:\")\n",
    "print(\"Ratio Precision Accuracy Recall F1\")\n",
    "for ratio, metrics in results.items():\n",
    "    print(f\"{ratio:}\\t{metrics['precision']:.4f}\\t{metrics['accuracy']:.4f}\\t{metrics['recall']:.4f}\\t{metrics['f1']:.4f}\")\n",
    "print(\"Average F1\",round(sum([ results[ratio]['f1'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Accuracy\",round(sum([ results[ratio]['accuracy'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Precision\",round(sum([ results[ratio]['precision'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Recall\",round(sum([ results[ratio]['recall'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "\n",
    "final_results_table.loc[len(final_results_table)] = ['SVM',\n",
    "                                                     round(sum([ results[ratio]['accuracy'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['precision'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['recall'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['f1'] for ratio in results.keys() ])/len(results.keys()),4)\n",
    "                                                    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 6: Reinforcement Learning (Q-learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for ratio 0.4\n",
      "[[2939  402]\n",
      " [ 461   82]]\n",
      "\n",
      "Confusion Matrix for ratio 0.3\n",
      "[[2193  306]\n",
      " [ 363   51]]\n",
      "\n",
      "Confusion Matrix for ratio 0.2\n",
      "[[1439  220]\n",
      " [ 244   39]]\n",
      "\n",
      "Confusion Matrix for ratio 0.1\n",
      "[[708 127]\n",
      " [116  20]]\n",
      "\n",
      "Results for test size ratio 0.4:\n",
      "Precision: 0.17\n",
      "Accuracy: 0.78\n",
      "Recall: 0.15\n",
      "F1: 0.16\n",
      "Results for test size ratio 0.3:\n",
      "Precision: 0.14\n",
      "Accuracy: 0.77\n",
      "Recall: 0.12\n",
      "F1: 0.13\n",
      "Results for test size ratio 0.2:\n",
      "Precision: 0.15\n",
      "Accuracy: 0.76\n",
      "Recall: 0.14\n",
      "F1: 0.14\n",
      "Results for test size ratio 0.1:\n",
      "Precision: 0.14\n",
      "Accuracy: 0.75\n",
      "Recall: 0.15\n",
      "F1: 0.14\n",
      "Results:\n",
      "Ratio Precision Accuracy Recall F1\n",
      "0.4\t0.1694\t0.7778\t0.1510\t0.1597\n",
      "0.3\t0.1429\t0.7703\t0.1232\t0.1323\n",
      "0.2\t0.1506\t0.7611\t0.1378\t0.1439\n",
      "0.1\t0.1361\t0.7497\t0.1471\t0.1413\n",
      "Average F1 0.1443\n",
      "Average Accuracy 0.7647\n",
      "Average Precision 0.1497\n",
      "Average Recall 0.1398\n"
     ]
    }
   ],
   "source": [
    "# Seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load data from a CSV file\n",
    "file_path = 'dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "# Preprocess data\n",
    "# Handling missing values (if any)\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert categorical columns to numerical values using one-hot encoding\n",
    "categorical_columns = ['Gender', 'Own_car', 'Own_property', 'Work_phone', 'Phone', 'Email', 'Income_type', 'Education_type', 'Family_status', 'Housing_type', 'Occupation_type']\n",
    "df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Feature selection\n",
    "# Assuming 'Target' is the target variable\n",
    "features = df.columns.difference(['ID', 'Target'])\n",
    "X = df[features]\n",
    "y = df['Target']\n",
    "\n",
    "# Q-learning algorithm\n",
    "def q_learning_train(X, y, episodes=1000, learning_rate=0.1, discount_factor=0.95, epsilon=0.1):\n",
    "    n_actions = 2  # Eligible or Not Eligible (0 or 1)\n",
    "    n_states = X.shape[0]\n",
    "    \n",
    "    # Initialize Q-table with zeros\n",
    "    Q = np.zeros((n_states, n_actions))\n",
    "    \n",
    "    for _ in range(episodes):\n",
    "        state = random.randint(0, n_states - 1)\n",
    "        while True:\n",
    "            if random.uniform(0, 1) < epsilon:  # epsilon is our exploration rate\n",
    "                action = random.randint(0, n_actions - 1)  # Explore\n",
    "            else:\n",
    "                action = np.argmax(Q[state, :])  # Exploit\n",
    "            \n",
    "            reward = 1 if y.iloc[state] == action else -1\n",
    "            \n",
    "            next_state = (state + 1) % n_states\n",
    "            Q[state, action] = Q[state, action] + learning_rate * (reward + discount_factor * np.max(Q[next_state, :]) - Q[state, action])\n",
    "            \n",
    "            state = next_state\n",
    "            if state == 0:\n",
    "                break\n",
    "    \n",
    "    return Q\n",
    "\n",
    "def q_learning_predict(Q, X):\n",
    "    '''Predicts the actions for each state in X (test data) using the Q-table.'''\n",
    "    y_pred = []\n",
    "    for state in range(X.shape[0]):\n",
    "        action = np.argmax(Q[state, :])\n",
    "        y_pred.append(action)\n",
    "    return np.array(y_pred)\n",
    "\n",
    "def print_confusion_matrix(cm, title):\n",
    "    print(f\"{title}\")\n",
    "    print(cm,end='\\n\\n')\n",
    "\n",
    "# training-testing ratios\n",
    "ratios = [0.4, 0.3, 0.2, 0.1]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for ratio in ratios:\n",
    "    # Split the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=42)\n",
    "\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Train Q-learning model\n",
    "    Q = q_learning_train(pd.DataFrame(X_train), y_train)\n",
    "    y_pred_q = q_learning_predict(Q, pd.DataFrame(X_test))\n",
    "\n",
    "    # Print confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred_q)\n",
    "    print_confusion_matrix(cm, f\"Confusion Matrix for ratio {ratio}\")\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision_q = precision_score(y_test, y_pred_q, zero_division=1)\n",
    "    accuracy_q = accuracy_score(y_test, y_pred_q)\n",
    "    recall_q = recall_score(y_test, y_pred_q)\n",
    "    f1_q = f1_score(y_test, y_pred_q)\n",
    "    \n",
    "    results[ratio] = {'precision': precision_q, 'accuracy': accuracy_q, 'recall': recall_q, 'f1': f1_q}\n",
    "\n",
    "# Print results\n",
    "for ratio in results:\n",
    "    print(f\"Results for test size ratio {ratio}:\")\n",
    "    for metric, value in results[ratio].items():\n",
    "        print(f\"{metric.capitalize()}: {value:.2f}\")\n",
    "\n",
    "# Print results\n",
    "print(\"Results:\")\n",
    "print(\"Ratio Precision Accuracy Recall F1\")\n",
    "for ratio, metrics in results.items():\n",
    "    print(f\"{ratio:}\\t{metrics['precision']:.4f}\\t{metrics['accuracy']:.4f}\\t{metrics['recall']:.4f}\\t{metrics['f1']:.4f}\")\n",
    "print(\"Average F1\",round(sum([ results[ratio]['f1'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Accuracy\",round(sum([ results[ratio]['accuracy'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Precision\",round(sum([ results[ratio]['precision'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Recall\",round(sum([ results[ratio]['recall'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "\n",
    "final_results_table.loc[len(final_results_table)] = ['RL/Q-Learning', \n",
    "                                                     round(sum([ results[ratio]['accuracy'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['precision'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['recall'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['f1'] for ratio in results.keys() ])/len(results.keys()),4)\n",
    "                                                    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our final comparison table tabulating our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANN</td>\n",
       "      <td>0.8049</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>0.1297</td>\n",
       "      <td>0.1499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.8561</td>\n",
       "      <td>0.2146</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.7641</td>\n",
       "      <td>0.1560</td>\n",
       "      <td>0.1775</td>\n",
       "      <td>0.1658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.8675</td>\n",
       "      <td>0.2167</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.8381</td>\n",
       "      <td>0.1580</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>0.0769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RL/Q-Learning</td>\n",
       "      <td>0.7647</td>\n",
       "      <td>0.1497</td>\n",
       "      <td>0.1398</td>\n",
       "      <td>0.1443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Accuracy  Precision  Recall  F1 Score\n",
       "0            ANN    0.8049     0.1885  0.1297    0.1499\n",
       "1            KNN    0.8561     0.2146  0.0333    0.0576\n",
       "2  Decision Tree    0.7641     0.1560  0.1775    0.1658\n",
       "3  Random Forest    0.8675     0.2167  0.0028    0.0055\n",
       "4            SVM    0.8381     0.1580  0.0516    0.0769\n",
       "5  RL/Q-Learning    0.7647     0.1497  0.1398    0.1443"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
