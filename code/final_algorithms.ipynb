{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Algorithms\n",
    "> By Sayed Afnan Khazi(01JST21CB036), Venkat Bhaskar(01JST21CB049), G Rutvik(01JST21CB012), Sai Sujith(01JST21CB033)\n",
    "- This notebook showcases the implementation of Artificial Neural Networks, K-Nearest Neighbors, Decision Trees, Random Forest, Support Vector Machines, and Reinforcement Learning (Q-learning) on a financial dataset containing Alibaba's stock prices for the past many years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: absl-py==2.1.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: appnope==0.1.4 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (0.1.4)\n",
      "Requirement already satisfied: asttokens==2.4.1 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (2.4.1)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (1.6.3)\n",
      "Requirement already satisfied: certifi==2024.2.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer==3.3.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (3.3.2)\n",
      "Requirement already satisfied: comm==0.2.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (0.2.2)\n",
      "Requirement already satisfied: debugpy==1.8.1 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (1.8.1)\n",
      "Requirement already satisfied: decorator==5.1.1 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (5.1.1)\n",
      "Requirement already satisfied: executing==2.0.1 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 10)) (2.0.1)\n",
      "Requirement already satisfied: flatbuffers==24.3.25 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 11)) (24.3.25)\n",
      "Requirement already satisfied: gast==0.5.4 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (0.5.4)\n",
      "Requirement already satisfied: google-pasta==0.2.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 13)) (0.2.0)\n",
      "Requirement already satisfied: grpcio==1.64.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 14)) (1.64.0)\n",
      "Requirement already satisfied: h5py==3.11.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 15)) (3.11.0)\n",
      "Requirement already satisfied: idna==3.7 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 16)) (3.7)\n",
      "Requirement already satisfied: ipykernel==6.29.4 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 17)) (6.29.4)\n",
      "Requirement already satisfied: ipython==8.24.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 18)) (8.24.0)\n",
      "Requirement already satisfied: jedi==0.19.1 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 19)) (0.19.1)\n",
      "Requirement already satisfied: joblib==1.4.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 20)) (1.4.2)\n",
      "Requirement already satisfied: jupyter_client==8.6.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 21)) (8.6.2)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 22)) (5.7.2)\n",
      "Requirement already satisfied: keras==3.3.3 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 23)) (3.3.3)\n",
      "Requirement already satisfied: libclang==18.1.1 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 24)) (18.1.1)\n",
      "Requirement already satisfied: Markdown==3.6 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 25)) (3.6)\n",
      "Requirement already satisfied: markdown-it-py==3.0.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 26)) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe==2.1.5 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 27)) (2.1.5)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 28)) (0.1.7)\n",
      "Requirement already satisfied: mdurl==0.1.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 29)) (0.1.2)\n",
      "Requirement already satisfied: ml-dtypes==0.3.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 30)) (0.3.2)\n",
      "Requirement already satisfied: namex==0.0.8 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 31)) (0.0.8)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 32)) (1.6.0)\n",
      "Requirement already satisfied: numpy==1.26.4 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 33)) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum==3.3.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 34)) (3.3.0)\n",
      "Requirement already satisfied: optree==0.11.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 35)) (0.11.0)\n",
      "Requirement already satisfied: packaging==24.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 36)) (24.0)\n",
      "Requirement already satisfied: pandas==2.2.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 37)) (2.2.2)\n",
      "Requirement already satisfied: parso==0.8.4 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 38)) (0.8.4)\n",
      "Requirement already satisfied: pexpect==4.9.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 39)) (4.9.0)\n",
      "Requirement already satisfied: platformdirs==4.2.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 40)) (4.2.2)\n",
      "Requirement already satisfied: prompt-toolkit==3.0.43 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 41)) (3.0.43)\n",
      "Requirement already satisfied: protobuf==4.25.3 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 42)) (4.25.3)\n",
      "Requirement already satisfied: psutil==5.9.8 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 43)) (5.9.8)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 44)) (0.7.0)\n",
      "Requirement already satisfied: pure-eval==0.2.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 45)) (0.2.2)\n",
      "Requirement already satisfied: Pygments==2.18.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 46)) (2.18.0)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 47)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz==2024.1 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 48)) (2024.1)\n",
      "Requirement already satisfied: pyzmq==26.0.3 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 49)) (26.0.3)\n",
      "Requirement already satisfied: requests==2.32.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 50)) (2.32.2)\n",
      "Requirement already satisfied: rich==13.7.1 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 51)) (13.7.1)\n",
      "Requirement already satisfied: scikit-learn==1.5.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 52)) (1.5.0)\n",
      "Requirement already satisfied: scipy==1.13.1 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 53)) (1.13.1)\n",
      "Requirement already satisfied: six==1.16.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 54)) (1.16.0)\n",
      "Requirement already satisfied: stack-data==0.6.3 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 55)) (0.6.3)\n",
      "Requirement already satisfied: tensorboard==2.16.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 56)) (2.16.2)\n",
      "Requirement already satisfied: tensorboard-data-server==0.7.2 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 57)) (0.7.2)\n",
      "Requirement already satisfied: tensorflow==2.16.1 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 58)) (2.16.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.37.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 59)) (0.37.0)\n",
      "Requirement already satisfied: termcolor==2.4.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 60)) (2.4.0)\n",
      "Requirement already satisfied: threadpoolctl==3.5.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 61)) (3.5.0)\n",
      "Requirement already satisfied: tornado==6.4 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 62)) (6.4)\n",
      "Requirement already satisfied: traitlets==5.14.3 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 63)) (5.14.3)\n",
      "Requirement already satisfied: typing_extensions==4.12.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 64)) (4.12.0)\n",
      "Requirement already satisfied: tzdata==2024.1 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 65)) (2024.1)\n",
      "Requirement already satisfied: urllib3==2.2.1 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 66)) (2.2.1)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 67)) (0.2.13)\n",
      "Requirement already satisfied: Werkzeug==3.0.3 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 68)) (3.0.3)\n",
      "Requirement already satisfied: wrapt==1.16.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from -r requirements.txt (line 69)) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from astunparse==1.6.3->-r requirements.txt (line 4)) (0.43.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/afnan/Programming/compare-algos-ai-class/.venv/lib/python3.11/site-packages (from tensorboard==2.16.2->-r requirements.txt (line 56)) (65.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install all the requirements\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 00:00:50.210600: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Importing all the requirements. \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, precision_score, accuracy_score, recall_score, f1_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_table = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 1: Artificial Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Confusion Matrix:\n",
      " [[3347   24]\n",
      " [ 694 2676]]\n",
      "\u001b[1m158/158\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Confusion Matrix:\n",
      " [[2504   24]\n",
      " [ 526 2002]]\n",
      "\u001b[1m106/106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Confusion Matrix:\n",
      " [[1678    8]\n",
      " [ 360 1325]]\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "Confusion Matrix:\n",
      " [[838   5]\n",
      " [186 657]]\n",
      "\n",
      "Metrics for fold 0.4:\n",
      "Precision: 0.99\n",
      "Accuracy: 0.89\n",
      "Recall: 0.79\n",
      "F1 Score: 0.88\n",
      "\n",
      "Metrics for fold 0.3:\n",
      "Precision: 0.99\n",
      "Accuracy: 0.89\n",
      "Recall: 0.79\n",
      "F1 Score: 0.88\n",
      "\n",
      "Metrics for fold 0.2:\n",
      "Precision: 0.99\n",
      "Accuracy: 0.89\n",
      "Recall: 0.79\n",
      "F1 Score: 0.88\n",
      "\n",
      "Metrics for fold 0.1:\n",
      "Precision: 0.99\n",
      "Accuracy: 0.89\n",
      "Recall: 0.78\n",
      "F1 Score: 0.87\n",
      "\n",
      "Classification Report for the last ratio:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.99      0.90       843\n",
      "           1       0.99      0.78      0.87       843\n",
      "\n",
      "    accuracy                           0.89      1686\n",
      "   macro avg       0.91      0.89      0.89      1686\n",
      "weighted avg       0.91      0.89      0.89      1686\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step\n",
      "The predicted eligibility for the next person is: Not Eligible\n",
      "Results:\n",
      "Ratio Precision Accuracy Recall F1\n",
      "0.4\t0.9911\t0.8935\t0.7941\t0.8817\n",
      "0.3\t0.9882\t0.8912\t0.7919\t0.8792\n",
      "0.2\t0.9940\t0.8908\t0.7864\t0.8781\n",
      "0.1\t0.9924\t0.8867\t0.7794\t0.8731\n",
      "Average F1 0.878\n",
      "Average Accuracy 0.8906\n",
      "Average Precision 0.9914\n",
      "Average Recall 0.7879\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_score, accuracy_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load data from a CSV file\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Preprocess data\n",
    "# Handling missing values (if any)\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert categorical columns to numerical values using one-hot encoding\n",
    "categorical_columns = ['Gender', 'Own_car', 'Own_property', 'Work_phone', 'Phone', 'Email', 'Income_type', 'Education_type', 'Family_status', 'Housing_type', 'Occupation_type']\n",
    "df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Feature selection\n",
    "features = df.columns.difference(['ID', 'Target'])\n",
    "X = df[features]\n",
    "y = df['Target']\n",
    "\n",
    "# Handle class imbalance using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "ratios = [0.4, 0.3, 0.2, 0.1]\n",
    "results = {}\n",
    "\n",
    "for ratio in ratios:\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=ratio, random_state=42, stratify=y_res)\n",
    "\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Initialize the ANN\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(units=64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=32, activation='relu'))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the ANN\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "    # Train the ANN\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision_q = precision_score(y_test, y_pred, zero_division=0)\n",
    "    accuracy_q = accuracy_score(y_test, y_pred)\n",
    "    recall_q = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1_q = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "    results[ratio] = {'precision': precision_q, 'accuracy': accuracy_q, 'recall': recall_q, 'f1': f1_q}\n",
    "\n",
    "# Display results\n",
    "for ratio, metrics in results.items():\n",
    "    print(f\"\\nMetrics for fold {ratio}:\")\n",
    "    print(f\"Precision: {metrics['precision']:.2f}\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.2f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.2f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.2f}\")\n",
    "\n",
    "\n",
    "# Detailed classification report for the last test size ratio\n",
    "print(\"\\nClassification Report for the last ratio:\\n\", classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Get the most recent data point and format it as a DataFrame\n",
    "last_data_point = df[features].iloc[-1].to_frame().T\n",
    "\n",
    "# Standardize the last data point\n",
    "last_data_point_scaled = scaler.transform(last_data_point)\n",
    "\n",
    "# Predict the eligibility for the next data point\n",
    "predicted_movement = model.predict(last_data_point_scaled)\n",
    "predicted_movement = (predicted_movement > 0.5).astype(int)\n",
    "\n",
    "# Interpret the result\n",
    "movement_label = \"Eligible\" if predicted_movement[0][0] == 1 else \"Not Eligible\"\n",
    "print(f'The predicted eligibility for the next person is: {movement_label}')\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(\"Results:\")\n",
    "print(\"Ratio Precision Accuracy Recall F1\")\n",
    "for ratio, metrics in results.items():\n",
    "    print(f\"{ratio:}\\t{metrics['precision']:.4f}\\t{metrics['accuracy']:.4f}\\t{metrics['recall']:.4f}\\t{metrics['f1']:.4f}\")\n",
    "print(\"Average F1\",round(sum([ results[ratio]['f1'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Accuracy\",round(sum([ results[ratio]['accuracy'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Precision\",round(sum([ results[ratio]['precision'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Recall\",round(sum([ results[ratio]['recall'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "\n",
    "final_results_table.loc[len(final_results_table)] = ['ANN', \n",
    "                                                     round(sum([ results[ratio]['accuracy'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['precision'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['recall'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['f1'] for ratio in results.keys() ])/len(results.keys()),4)\n",
    "                                                    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 2: K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from a CSV file\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Preprocess data\n",
    "# Handling missing values (if any)\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert categorical columns to numerical values using one-hot encoding\n",
    "categorical_columns = ['Gender', 'Own_car', 'Own_property', 'Work_phone', 'Phone', 'Email', 'Income_type', 'Education_type', 'Family_status', 'Housing_type', 'Occupation_type']\n",
    "df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Feature selection\n",
    "# Assuming 'Target' is the target variable\n",
    "features = df.columns.difference(['ID', 'Target'])\n",
    "X = df[features]\n",
    "y = df['Target']\n",
    "\n",
    "# Training-testing ratios\n",
    "ratios = [0.4, 0.3, 0.2, 0.1]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for ratio in ratios:\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=0)\n",
    "    \n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Initialize and train the KNN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=2)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix for ratio {ratio}:\\n\", cm)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision_q = precision_score(y_test, y_pred, zero_division=0)\n",
    "    accuracy_q = accuracy_score(y_test, y_pred)\n",
    "    recall_q = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1_q = f1_score(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    results[ratio] = {'precision': precision_q, 'accuracy': accuracy_q, 'recall': recall_q, 'f1': f1_q}\n",
    "\n",
    "# Display results\n",
    "for ratio, metrics in results.items():\n",
    "    print(f\"\\nMetrics for test size ratio {ratio}:\")\n",
    "    print(f\"Precision: {metrics['precision']:.2f}\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.2f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.2f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.2f}\")\n",
    "\n",
    "# Detailed classification report for the last test size ratio\n",
    "print(\"\\nClassification Report for the last ratio:\\n\", classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Get the most recent data point and format it as a DataFrame\n",
    "last_data_point = df[features].iloc[-1].to_frame().T\n",
    "\n",
    "# Standardize the last data point\n",
    "last_data_point_scaled = scaler.transform(last_data_point)\n",
    "\n",
    "# Predict the eligibility for the next data point\n",
    "predicted_eligibility = knn.predict(last_data_point_scaled)\n",
    "\n",
    "# Interpret the result\n",
    "eligibility_label = \"Eligible\" if predicted_eligibility[0] == 1 else \"Not Eligible\"\n",
    "print(f'The predicted eligibility for the next person is: {eligibility_label}')\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(\"Results:\")\n",
    "print(\"Ratio Precision Accuracy Recall F1\")\n",
    "for ratio, metrics in results.items():\n",
    "    print(f\"{ratio:}\\t{metrics['precision']:.4f}\\t{metrics['accuracy']:.4f}\\t{metrics['recall']:.4f}\\t{metrics['f1']:.4f}\")\n",
    "print(\"Average F1\",round(sum([ results[ratio]['f1'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Accuracy\",round(sum([ results[ratio]['accuracy'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Precision\",round(sum([ results[ratio]['precision'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Recall\",round(sum([ results[ratio]['recall'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "\n",
    "final_results_table.loc[len(final_results_table)] = ['KNN', \n",
    "                                                     round(sum([ results[ratio]['accuracy'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['precision'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['recall'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['f1'] for ratio in results.keys() ])/len(results.keys()),4)\n",
    "                                                    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 3: Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from the new CSV file\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# List of categorical features to encode\n",
    "categorical_features = ['Income_type', 'Education_type', 'Family_status', 'Housing_type', 'Occupation_type']\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for feature in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "    label_encoders[feature] = le\n",
    "\n",
    "# Feature selection - excluding 'ID' and 'Target'\n",
    "features = [col for col in df.columns if col not in ['ID', 'Target']]\n",
    "X = df[features]\n",
    "y = df['Target']\n",
    "\n",
    "# Training-testing ratios\n",
    "ratios = [0.4, 0.3, 0.2, 0.1]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for ratio in ratios:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=0)\n",
    "\n",
    "    # Model training\n",
    "    classifier = DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix for ratio {ratio}:\\n\", cm)\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision_q = precision_score(y_test, y_pred)\n",
    "    accuracy_q = accuracy_score(y_test, y_pred)\n",
    "    recall_q = recall_score(y_test, y_pred)\n",
    "    f1_q = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results[ratio] = {'precision': precision_q, 'accuracy': accuracy_q, 'recall': recall_q, 'f1': f1_q}\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Get the most recent data point and format it as a DataFrame\n",
    "last_data_point = df[features].iloc[-1].to_frame().T\n",
    "\n",
    "# Predict the eligibility for the next individual\n",
    "predicted_eligibility = classifier.predict(last_data_point)\n",
    "\n",
    "# Interpret the result\n",
    "eligibility_label = \"Eligible\" if predicted_eligibility[0] == 1 else \"Not Eligible\"\n",
    "print(f'The predicted eligibility for the next individual is: {eligibility_label}')\n",
    "\n",
    "# Print results\n",
    "print(\"Results:\")\n",
    "print(\"Ratio Precision Accuracy Recall F1\")\n",
    "for ratio, metrics in results.items():\n",
    "    print(f\"{ratio:}\\t{metrics['precision']:.4f}\\t{metrics['accuracy']:.4f}\\t{metrics['recall']:.4f}\\t{metrics['f1']:.4f}\")\n",
    "print(\"Average F1\",round(sum([ results[ratio]['f1'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Accuracy\",round(sum([ results[ratio]['accuracy'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Precision\",round(sum([ results[ratio]['precision'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Recall\",round(sum([ results[ratio]['recall'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "\n",
    "final_results_table.loc[len(final_results_table)] = ['Decision Tree', \n",
    "                                                     round(sum([ results[ratio]['accuracy'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['precision'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['recall'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['f1'] for ratio in results.keys() ])/len(results.keys()),4)\n",
    "                                                    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 4: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from the new CSV file\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# List of categorical features to encode\n",
    "categorical_features = ['Income_type', 'Education_type', 'Family_status', 'Housing_type', 'Occupation_type']\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "for feature in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    df[feature] = le.fit_transform(df[feature])\n",
    "    label_encoders[feature] = le\n",
    "\n",
    "# Feature selection - excluding 'ID' and 'Target'\n",
    "features = [col for col in df.columns if col not in ['ID', 'Target']]\n",
    "X = df[features]\n",
    "y = df['Target']\n",
    "\n",
    "# Training-testing ratios\n",
    "ratios = [0.4, 0.3, 0.2, 0.1]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for ratio in ratios:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=0)\n",
    "\n",
    "    # Model training\n",
    "    classifier = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state=0)\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = classifier.predict(X_test)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix for ratio {ratio}:\\n\", cm)\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision_q = precision_score(y_test, y_pred)\n",
    "    accuracy_q = accuracy_score(y_test, y_pred)\n",
    "    recall_q = recall_score(y_test, y_pred)\n",
    "    f1_q = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results[ratio] = {'precision': precision_q, 'accuracy': accuracy_q, 'recall': recall_q, 'f1': f1_q}\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Get the most recent data point and format it as a DataFrame\n",
    "last_data_point = df[features].iloc[-1].to_frame().T\n",
    "\n",
    "# Predict the eligibility for the next individual\n",
    "predicted_eligibility = classifier.predict(last_data_point)\n",
    "\n",
    "# Interpret the result\n",
    "eligibility_label = \"Eligible\" if predicted_eligibility[0] == 1 else \"Not Eligible\"\n",
    "print(f'The predicted eligibility for the next individual is: {eligibility_label}')\n",
    "\n",
    "# Print results\n",
    "print(\"Results:\")\n",
    "print(\"Ratio Precision Accuracy Recall F1\")\n",
    "for ratio, metrics in results.items():\n",
    "    print(f\"{ratio:}\\t{metrics['precision']:.4f}\\t{metrics['accuracy']:.4f}\\t{metrics['recall']:.4f}\\t{metrics['f1']:.4f}\")\n",
    "print(\"Average F1\",round(sum([ results[ratio]['f1'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Accuracy\",round(sum([ results[ratio]['accuracy'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Precision\",round(sum([ results[ratio]['precision'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Recall\",round(sum([ results[ratio]['recall'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "\n",
    "final_results_table.loc[len(final_results_table)] = ['Random Forest', \n",
    "                                                     round(sum([ results[ratio]['accuracy'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['precision'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['recall'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['f1'] for ratio in results.keys() ])/len(results.keys()),4)\n",
    "                                                    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 5: Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from a CSV file\n",
    "df = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Preprocess data\n",
    "# Handling missing values (if any)\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert categorical columns to numerical values using one-hot encoding\n",
    "categorical_columns = ['Gender', 'Own_car', 'Own_property', 'Work_phone', 'Phone', 'Email', 'Income_type', 'Education_type', 'Family_status', 'Housing_type', 'Occupation_type']\n",
    "df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Feature selection\n",
    "# Assuming 'Target' is the target variable\n",
    "features = df.columns.difference(['ID', 'Target'])\n",
    "X = df[features]\n",
    "y = df['Target']\n",
    "\n",
    "# Training-testing ratios\n",
    "ratios = [0.4, 0.3, 0.2, 0.1]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for ratio in ratios:\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=0)\n",
    "    \n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Initialize and train the SVM classifier\n",
    "    svm_classifier = SVC(kernel='sigmoid', random_state=0)\n",
    "    svm_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = svm_classifier.predict(X_test)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Confusion Matrix for ratio {ratio}:\\n\", cm)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision_q = precision_score(y_test, y_pred, zero_division=0)\n",
    "    accuracy_q = accuracy_score(y_test, y_pred)\n",
    "    recall_q = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1_q = f1_score(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    results[ratio] = {'precision': precision_q, 'accuracy': accuracy_q, 'recall': recall_q, 'f1': f1_q}\n",
    "\n",
    "# Display results\n",
    "for ratio, metrics in results.items():\n",
    "    print(f\"\\nMetrics for test size ratio {ratio}:\")\n",
    "    print(f\"Precision: {metrics['precision']:.2f}\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.2f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.2f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.2f}\")\n",
    "\n",
    "# Detailed classification report for the last test size ratio\n",
    "print(\"\\nClassification Report for the last ratio:\\n\", classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Get the most recent data point and format it as a DataFrame\n",
    "last_data_point = df[features].iloc[-1].to_frame().T\n",
    "\n",
    "# Standardize the last data point\n",
    "last_data_point_scaled = scaler.transform(last_data_point)\n",
    "\n",
    "# Predict the eligibility for the next data point\n",
    "predicted_eligibility = svm_classifier.predict(last_data_point_scaled)\n",
    "\n",
    "# Interpret the result\n",
    "eligibility_label = \"Eligible\" if predicted_eligibility[0] == 1 else \"Not Eligible\"\n",
    "print(f'The predicted eligibility for the next data point is: {eligibility_label}')\n",
    "\n",
    "# Print results\n",
    "print(\"Results:\")\n",
    "print(\"Ratio Precision Accuracy Recall F1\")\n",
    "for ratio, metrics in results.items():\n",
    "    print(f\"{ratio:}\\t{metrics['precision']:.4f}\\t{metrics['accuracy']:.4f}\\t{metrics['recall']:.4f}\\t{metrics['f1']:.4f}\")\n",
    "print(\"Average F1\",round(sum([ results[ratio]['f1'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Accuracy\",round(sum([ results[ratio]['accuracy'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Precision\",round(sum([ results[ratio]['precision'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Recall\",round(sum([ results[ratio]['recall'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "\n",
    "final_results_table.loc[len(final_results_table)] = ['SVM',\n",
    "                                                     round(sum([ results[ratio]['accuracy'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['precision'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['recall'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['f1'] for ratio in results.keys() ])/len(results.keys()),4)\n",
    "                                                    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 6: Reinforcement Learning (Q-learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load data from a CSV file\n",
    "file_path = 'dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "# Preprocess data\n",
    "# Handling missing values (if any)\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert categorical columns to numerical values using one-hot encoding\n",
    "categorical_columns = ['Gender', 'Own_car', 'Own_property', 'Work_phone', 'Phone', 'Email', 'Income_type', 'Education_type', 'Family_status', 'Housing_type', 'Occupation_type']\n",
    "df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Feature selection\n",
    "# Assuming 'Target' is the target variable\n",
    "features = df.columns.difference(['ID', 'Target'])\n",
    "X = df[features]\n",
    "y = df['Target']\n",
    "\n",
    "# Q-learning algorithm\n",
    "def q_learning_train(X, y, episodes=1000, learning_rate=0.1, discount_factor=0.95, epsilon=0.1):\n",
    "    n_actions = 2  # Eligible or Not Eligible (0 or 1)\n",
    "    n_states = X.shape[0]\n",
    "    \n",
    "    # Initialize Q-table with zeros\n",
    "    Q = np.zeros((n_states, n_actions))\n",
    "    \n",
    "    for _ in range(episodes):\n",
    "        state = random.randint(0, n_states - 1)\n",
    "        while True:\n",
    "            if random.uniform(0, 1) < epsilon:  # epsilon is our exploration rate\n",
    "                action = random.randint(0, n_actions - 1)  # Explore\n",
    "            else:\n",
    "                action = np.argmax(Q[state, :])  # Exploit\n",
    "            \n",
    "            reward = 1 if y.iloc[state] == action else -1\n",
    "            \n",
    "            next_state = (state + 1) % n_states\n",
    "            Q[state, action] = Q[state, action] + learning_rate * (reward + discount_factor * np.max(Q[next_state, :]) - Q[state, action])\n",
    "            \n",
    "            state = next_state\n",
    "            if state == 0:\n",
    "                break\n",
    "    \n",
    "    return Q\n",
    "\n",
    "def q_learning_predict(Q, X):\n",
    "    '''Predicts the actions for each state in X (test data) using the Q-table.'''\n",
    "    y_pred = []\n",
    "    for state in range(X.shape[0]):\n",
    "        action = np.argmax(Q[state, :])\n",
    "        y_pred.append(action)\n",
    "    return np.array(y_pred)\n",
    "\n",
    "def print_confusion_matrix(cm, title):\n",
    "    print(f\"{title}\")\n",
    "    print(cm,end='\\n\\n')\n",
    "\n",
    "# training-testing ratios\n",
    "ratios = [0.4, 0.3, 0.2, 0.1]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for ratio in ratios:\n",
    "    # Split the dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=42)\n",
    "\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Train Q-learning model\n",
    "    Q = q_learning_train(pd.DataFrame(X_train), y_train)\n",
    "    y_pred_q = q_learning_predict(Q, pd.DataFrame(X_test))\n",
    "\n",
    "    # Print confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred_q)\n",
    "    print_confusion_matrix(cm, f\"Confusion Matrix for ratio {ratio}\")\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision_q = precision_score(y_test, y_pred_q, zero_division=1)\n",
    "    accuracy_q = accuracy_score(y_test, y_pred_q)\n",
    "    recall_q = recall_score(y_test, y_pred_q)\n",
    "    f1_q = f1_score(y_test, y_pred_q)\n",
    "    \n",
    "    results[ratio] = {'precision': precision_q, 'accuracy': accuracy_q, 'recall': recall_q, 'f1': f1_q}\n",
    "\n",
    "# Print results\n",
    "for ratio in results:\n",
    "    print(f\"Results for test size ratio {ratio}:\")\n",
    "    for metric, value in results[ratio].items():\n",
    "        print(f\"{metric.capitalize()}: {value:.2f}\")\n",
    "\n",
    "# Print results\n",
    "print(\"Results:\")\n",
    "print(\"Ratio Precision Accuracy Recall F1\")\n",
    "for ratio, metrics in results.items():\n",
    "    print(f\"{ratio:}\\t{metrics['precision']:.4f}\\t{metrics['accuracy']:.4f}\\t{metrics['recall']:.4f}\\t{metrics['f1']:.4f}\")\n",
    "print(\"Average F1\",round(sum([ results[ratio]['f1'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Accuracy\",round(sum([ results[ratio]['accuracy'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Precision\",round(sum([ results[ratio]['precision'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "print(\"Average Recall\",round(sum([ results[ratio]['recall'] for ratio in results.keys() ])/len(results.keys()),4))\n",
    "\n",
    "final_results_table.loc[len(final_results_table)] = ['RL/Q-Learning', \n",
    "                                                     round(sum([ results[ratio]['accuracy'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['precision'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['recall'] for ratio in results.keys() ])/len(results.keys()),4),\n",
    "                                                     round(sum([ results[ratio]['f1'] for ratio in results.keys() ])/len(results.keys()),4)\n",
    "                                                    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our final comparison table tabulating our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
